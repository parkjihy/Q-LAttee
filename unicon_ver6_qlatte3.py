# -*- coding: utf-8 -*-
"""unicon_ver2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G_U3Mg51q8QX--tFmUpyO92nLLNbBDoM
"""

import pandas as pd
import pickle
import pandas as pd
import os
import numpy as np
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')
from datetime import timedelta
import gc
from sklearn.model_selection import train_test_split,KFold,GroupKFold
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error
import timeit


"""# Data import"""
df = pd.read_csv("/home/unicorn/unicon/household_data_1min_singleindex.csv", encoding='ISO-8859-1')


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import seaborn as sns

"""# feature engneering"""
# "timestamp" 열의 데이터 타입을 문자열로 변환

    
# Importing datetime and pytz module
from datetime import datetime
import pytz

import datetime

targets = ['y1','y2','y3','y4','y5']
features = ['Month', 'Day', 'Hour', 'Minute']

features_ = ['Month', 'Day', 'Hour', 'Minute']

import re
data=df

from pandas.core.frame import Axis
X = data[['Month', 'Day', 'Hour', 'Minute']].values.astype(float)

y=data[['y1','y2','y3','y4','y5']].values.astype(float)



"""# LSTNattention"""

from sklearn.model_selection import train_test_split

# Assuming you have your data in X (features) and y (labels/targets) arrays
# X and y should be numpy arrays or pandas DataFrames/Series

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


import torch
from torch import nn
import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Dataset
import time

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class Attention(nn.Module):
    def __init__(self, hidden_dim):
        super(Attention, self).__init__()
        self.hidden_dim = hidden_dim
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, inputs):
        attn_weights = torch.tanh(self.fc(inputs))
        soft_attn_weights = torch.softmax(attn_weights, 1)
        context = inputs * soft_attn_weights
        context = context.sum(1)
        return context

class AttnLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(AttnLSTM, self).__init__()
        self.hidden_dim = hidden_dim
        self.lstm = nn.LSTM(input_size=input_dim,
                            hidden_size=hidden_dim,
                            batch_first=True,
                            bidirectional=True)
        self.attention_layer = Attention(hidden_dim * 2)
        self.output_layer = nn.Linear(hidden_dim * 2, 5)

    def forward(self, x):
       lstm_out, _ = self.lstm(x)
       attn_out = self.attention_layer(lstm_out)
       final_output = self.output_layer(attn_out)
       return final_output

class EnergyDataset(Dataset):
    def __init__(self, features, targets):
        self.features = torch.tensor(features, dtype=torch.float32)
        self.targets = torch.tensor(targets, dtype=torch.float32)

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        feature = self.features[idx]
        target = self.targets[idx]
        return feature, target
def calculate_MAPE(actuals, predictions):
    # Find indices where both actuals and predictions are non-zero
    non_zero_indices = np.logical_and(actuals != 0, predictions != 0)
    
    # Calculate absolute percentage errors
    absolute_errors = np.abs((actuals - predictions) / actuals)
    
    # Filter absolute errors using non-zero indices
    absolute_errors_filtered = absolute_errors[non_zero_indices]
    
    # Calculate MAPE
    MAPE = np.mean(absolute_errors_filtered) * 100
    return MAPE

def calculate_MASE(actuals, predictions):
    n = len(actuals)
    d = np.sum(np.abs(np.diff(actuals)))
    errors = np.abs(actuals - predictions)
    return (1 / n) * np.sum(errors) / (d / (n - 1))

# Load the dataset
from pandas.core.frame import Axis
from torch.utils.data import DataLoader, Dataset
# Load data into a DataFrame

# Define batch size
batch_size = 32

# Prepare the training dataset and dataloader
from sklearn.model_selection import train_test_split

# Assuming 'data' is your pandas DataFrame containing your dataset

# Split the data into training and testing sets
# Create training and test datasets
train_dataset = EnergyDataset(X_train, y_train)
test_dataset = EnergyDataset(X_test, y_test)

# Create DataLoader instances
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Parameters
# Parameters
input_size = X_train.shape[1]
hidden_units = 10
num_epochs = 10


"""# distribution Quantization"""

import torch
from torch import nn
import pandas as pd
import time
from sklearn.metrics import mean_squared_error
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
import numpy as np

predictions1 = []
actuals1 = []
predictions2 = []
actuals2 = []
predictions3 = []
actuals3 = []

class Attention(nn.Module):
    def __init__(self, hidden_dim):
        super(Attention, self).__init__()
        self.hidden_dim = hidden_dim
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, inputs):
        attn_weights = torch.tanh(self.fc(inputs))
        soft_attn_weights = torch.softmax(attn_weights, 1)

        context = inputs * soft_attn_weights
        context = context.sum(1)

        return context

class AttnLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(AttnLSTM, self).__init__()

        self.hidden_dim = hidden_dim

        # Define the LSTM layer
        self.lstm = nn.LSTM(input_size=input_dim,
                            hidden_size=hidden_dim,
                            batch_first=True,
                            bidirectional=True)  # make it bidirectional

         # Define the attention layer
        self.attention_layer = Attention(hidden_dim * 2)  # adjust input dimension

         # Define the output layer
        self.output_layer = nn.Linear(hidden_dim*2, 5)   # adjust input dimension

    def forward(self,x):
       lstm_out,_=self.lstm(x)
       attn_out=self.attention_layer(lstm_out)
       final_output=self.output_layer(attn_out)

       return final_output, attn_out

def to_prob_dist(vectors):
    # Apply the softmax function along the last dimension
    return torch.softmax(vectors, dim=-1)


from torch.utils.data import DataLoader, Dataset

class EnergyDataset(Dataset):
    def __init__(self, features, targets):
        self.features = torch.tensor(features, dtype=torch.float32)
        self.targets = torch.tensor(targets, dtype=torch.float32)

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        feature = self.features[idx]
        target = self.targets[idx]
        return feature, target


class VectorQuantizer(nn.Module):
    def __init__(self, num_embeddings, embedding_dim):
        super(VectorQuantizer, self).__init__()
        self.embedding_dim = embedding_dim
        self.num_embeddings = num_embeddings

        # Initialize the embeddings which represent the codewords in the codebook
        self.embeddings = nn.Embedding(self.num_embeddings, self.embedding_dim)
        self.embeddings.weight.data.uniform_(-1/self.num_embeddings, 1/self.num_embeddings)

    def forward(self, inputs):
        # Compute distances to the embeddings
        distances = (torch.sum(inputs**2, dim=1, keepdim=True)
                    + torch.sum(self.embeddings.weight**2, dim=1)
                    - 2 * torch.matmul(inputs.float(), self.embeddings.weight.t()))

        # Find the closest embeddings
        _, indices = torch.min(distances.float(), dim=1)

         # Use the indices to gather the embeddings from the codebook
        quantized = self.embeddings(indices) + 0.0001 * inputs


        return quantized

def kl_divergence(p, q):
    return torch.sum(p * torch.log(p / q), dim=-1)

def js_divergence(p, q):
    m = 0.5 * (p + q)
    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)
    
def calculate_MAPE(actuals, predictions):
    # Find indices where both actuals and predictions are non-zero
    non_zero_indices = np.logical_and(actuals != 0, predictions != 0)
    
    # Calculate absolute percentage errors
    absolute_errors = np.abs((actuals - predictions) / actuals)
    
    # Filter absolute errors using non-zero indices
    absolute_errors_filtered = absolute_errors[non_zero_indices]
    
    # Calculate MAPE
    MAPE = np.mean(absolute_errors_filtered) * 100
    return MAPE

def calculate_MASE(actuals, predictions):
    n = len(actuals)
    d = np.sum(np.abs(np.diff(actuals)))
    errors = np.abs(actuals - predictions)
    return (1 / n) * np.sum(errors) / (d / (n - 1))

batch_size=32


# Parameters
hidden_units=7
# Load the context vectors from a file
context_vectors_np = np.load("/home/unicorn/unicon/context_vectors.npy")

num_epochs=5

# Create model instance
model1=AttnLSTM(input_size ,hidden_units)
# Loss function and optimizer
criterion=torch.nn.MSELoss()
optimizer=torch.optim.Adam(model1.parameters(),lr=0.0001)

# Create a VectorQuantizer instance
num_embeddings =  10  # Number of codewords in the codebook (hyperparameter)
embedding_dim = hidden_units*2   # Dimension of each codeword (should match with context vector dimension)

quantizer = VectorQuantizer(num_embeddings=num_embeddings,
                            embedding_dim=embedding_dim).to('cpu')


#optimizer=torch.optim.Adam([p for p in quantized_model.parameters() if p.requires_grad], lr=0.0001)


model1.to('cpu')
context_vectors_before = []
model1.train()
# Training loop1
start_time1 = time.time()
for epoch in range(num_epochs):
#for epoch in range():
    total_loss = 0
    total_squared_error = 0.0

    for features, targets in train_dataloader:
        # Add an extra dimension for sequence length
        features = features.unsqueeze(1).to('cpu')
        targets = targets.to('cpu')

        # Forward pass


        outputs, context_vector = model1(features.float())  # Get context vector
        #context_vectors_before.append(context_vector.detach().numpy())
        # Save the context vectors somewhere for later analysis
        mse_loss = criterion(outputs.squeeze(), targets.float())

        # Backward pass and optimization step
        optimizer.zero_grad()
        mse_loss.backward()
        optimizer.step()

        total_squared_error += ((outputs - targets)**2).sum().item()
        total_loss += mse_loss.item()
    avg_loss=total_loss/len(train_dataloader)
    #rmse=(total_squared_error / len(train_dataset))**0.5

    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}')

end_time1 = time.time()
training_time1 = end_time1 - start_time1
print(f"Model 1 Training Time: {training_time1:.4f} seconds")

# Prepare the test dataset and dataloader
#test_dataset = EnergyDataset('test.csv')
#test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

context_vectors_after = []

model1.eval()
start_time1 = time.time()
with torch.no_grad():
    total_loss = 0
    total_squared_error = 0.0

    for features, targets in test_dataloader:

        features = features.unsqueeze(1).to('cpu')
        targets = targets.to('cpu')

        outputs, context_vector = model1(features.float())

        context_vectors_before.append(context_vector.detach().numpy())


        predictions1.append(outputs.numpy())
        actuals1.append(targets.numpy())

    predictions1=np.concatenate(predictions1,axis=0)
    actuals1=np.concatenate(actuals1,axis=0)
    # Calculate MAPE and MSLE for each model
    mape_model1 = calculate_MAPE(actuals1, predictions1)
    print("Model 1:")
    print(f"MAPE: {mape_model1:.2f}%")
    # Calculate MASE
    MASE1 = calculate_MASE(actuals1, predictions1)

    print(f"MASE: {MASE1:.4f}")
    end_time1 = time.time()


# Initialize lists to save predictions and actual values

# Switch to evaluation mode
# Ensure the model is in evaluation mode
  ## Move model to CPU before applying dynamic Quantization
model2 = AttnLSTM(input_size ,hidden_units)
model2.train()
quantized_model=torch.quantization.quantize_dynamic(
    model2,
    {nn.LSTM, nn.Linear},
    dtype=torch.qint8)



  # move model to cpu

# Define a function to calibrate the model with representative data
def calibrate(model, dataloader):
    with torch.no_grad():
        for features_, targets in dataloader:
            features_ = features_.unsqueeze(1).to('cpu')  # move data to cpu
            _ = model2(features_.float())


optimizer = torch.optim.Adam([p for p in model2.parameters() if p.requires_grad], lr=0.0001)
  ## We need to create a new optimizer as our old one is still attached to our original model

# Calibrate the model using training data loader
#calibrate(quantized_model, train_dataloader)

print("Quantized Model:")
print(quantized_model)
context_vectors_middle = []
model2 = quantized_model


model2.eval()
start_time2 = time.time()
with torch.no_grad():
    total_loss = 0
    total_squared_error = 0.0

    for features_, targets in test_dataloader:

        features_ = features_.unsqueeze(1).to('cpu')
        targets = targets.to('cpu')

        outputs, context_vector = model2(features_.float())

        context_vectors_middle.append(context_vector.detach().numpy())


        predictions2.append(outputs.numpy())
        actuals2.append(targets.numpy())

    predictions2=np.concatenate(predictions2,axis=0)
    actuals2=np.concatenate(actuals2,axis=0)
    mape_model2 = calculate_MAPE(actuals2, predictions2)

    print("Model 2:")
    print(f"MAPE: {mape_model2:.2f}%")
        # Calculate MASE
    MASE2 = calculate_MASE(actuals2, predictions2)

    print(f"MASE: {MASE2:.4f}")
end_time2 = time.time()
evaluation_time2 = end_time2 - start_time2
print(f"Model 2 Evaluation Time: {evaluation_time2:.4f} seconds")

num_epochs=5
model3 = AttnLSTM(input_size ,hidden_units)
model3.train()
start_time3 = time.time()
for epoch in range(num_epochs):
    total_loss = 0
    total_squared_error = 0.0

    for features_, targets in train_dataloader:
        # Add an extra dimension for sequence length
        features_ = features_.unsqueeze(1).to('cpu')
        targets = targets.to('cpu')

        # Forward pass and compute loss
        outputs, context_vector = model3(features_.float())
        #context_vectors_middle.append(context_vector.detach().numpy())
         # Save the context vectors somewhere for later analysis
        quantized_context_vector_before_training=quantizer(context_vector.detach().to('cpu'))

         # Convert vectors to probability distributions
        context_vectors_prob = to_prob_dist(context_vector)
        quantized_context_vector_prob = to_prob_dist(quantized_context_vector_before_training)

         # Compute loss
        mse_loss=criterion(outputs.squeeze(),targets.float())

         # Compute KL divergence between original and quantized distributions
        kl_loss=kl_divergence(context_vectors_prob, quantized_context_vector_prob).mean()

         # Combine the losses
        loss=mse_loss + kl_loss
        #loss = kl_loss
         # Backward pass and optimization step
        optimizer.zero_grad()
        loss.backward()

        optimizer.step()

        total_squared_error += ((outputs - targets)**2).sum().item()
        total_loss += loss.item()

    avg_loss = total_loss / len(train_dataloader)
    #rmse = (total_squared_error / len(train_dataset))**0.5

    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}')
end_time3_training = time.time()
training_time3 = end_time3_training - start_time3
print(f"Model 3 Training Time: {training_time3:.4f} seconds")



# Prepare the test dataset and dataloader

#test_dataset = EnergyDataset('test.csv')
#test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Initialize lists to save predictions and actual values
predictions = []
actuals = []



model3.eval()
start_time3 = time.time()
with torch.no_grad():
    total_loss = 0
    total_squared_error = 0.0

    for features_, targets in test_dataloader:

        features_ = features_.unsqueeze(1).to('cpu')
        targets = targets.to('cpu')

        outputs, context_vector = model3(features_.float())

        context_vectors_after.append(context_vector.detach().numpy())


        predictions3.append(outputs.numpy())
        actuals3.append(targets.numpy())

    predictions3=np.concatenate(predictions3,axis=0)
    actuals3=np.concatenate(actuals3,axis=0)

    mape_model3 = calculate_MAPE(actuals3, predictions2)

    print("Model 3:")
    print(f"MAPE: {mape_model3:.2f}%")
        # Calculate MASE
    MASE3 = calculate_MASE(actuals3, predictions3)

    print(f"MASE: {MASE3:.4f}")
    end_time3 = time.time()




end_time = time.time()  # End timer

total_inference_time = end_time - start_time  # Total inference time

avg_inference_time_per_sample = total_inference_time / len(test_dataset)  # Average inference time per sample

print(f"Total Inference Time: {total_inference_time:.4f} seconds")
print(f"Average Inference Time Per Sample: {avg_inference_time_per_sample:.6f} seconds")

import numpy as np
import matplotlib.pyplot as plt

# Convert lists to NumPy arrays
context_vectors_before_np = np.concatenate(context_vectors_before)
context_vectors_middle_np = np.concatenate(context_vectors_middle)
context_vectors_after_np = np.concatenate(context_vectors_after)

# Flatten the arrays for histogram
context_vectors_before_flat = context_vectors_before_np.flatten()
context_vectors_middle_flat = context_vectors_middle_np.flatten()
context_vectors_after_flat = context_vectors_after_np.flatten()

# Plot histograms
plt.figure(figsize=(30, 15))
plt.subplot(1, 3, 1)
plt.hist(context_vectors_before_flat, bins=200)
plt.title('Original model (Distribution Before Quantization)')
plt.tick_params(axis='both', which='major', labelsize=20)
plt.xlim(-0.25, 0.25)
plt.subplot(1, 3, 2)
plt.hist(context_vectors_middle_flat, bins=200)
plt.title('Quantized Model (Distribution Middle Quantization)')
plt.tick_params(axis='both', which='major', labelsize=20)
plt.xlim(-0.25, 0.25)
plt.subplot(1, 3, 3)
plt.hist(context_vectors_after_flat, bins=200)
plt.title('Q-LAtte Model (Distribution After Quantization)')
plt.tick_params(axis='both', which='major', labelsize=20)
plt.xlim(-0.25, 0.25)
#plt.show()
plt.savefig('/home/unicorn/unicon/model_skeww.png')



import matplotlib.pyplot as plt
#model1
# Set a Seaborn style (optional but enhances aesthetics)
sns.set(style="whitegrid")

# Plot the actual values
plt.plot(actuals1, label='Actual Values', color='blue')

# Plot the predicted values
plt.plot(predictions1, label='Predicted Values', color='orange')

# Add labels and title
plt.xlabel('Sample Index', fontsize=14)
plt.ylabel('Energy Consumption', fontsize=14)
plt.title('Actual vs Predicted Total Energy Consumption', fontsize=16)

# Add legend
plt.legend(fontsize=12)

# Customize the plot appearance
plt.grid(True, linestyle='--', alpha=0.3)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

# Save the plot to a file (e.g., a PNG file)
plt.savefig('/home/unicorn/unicon/model1.png', bbox_inches='tight')

#model1
# Set a Seaborn style (optional but enhances aesthetics)
sns.set(style="whitegrid")

# Plot the actual values
plt.plot(actuals2, label='Actual Values', color='blue')

# Plot the predicted values
plt.plot(predictions2, label='Predicted Values', color='orange')

# Add labels and title
plt.xlabel('Sample Index', fontsize=14)
plt.ylabel('Energy Consumption', fontsize=14)
plt.title('Actual vs Predicted Total Energy Consumption', fontsize=16)

# Add legend
plt.legend(fontsize=12)

# Customize the plot appearance
plt.grid(True, linestyle='--', alpha=0.3)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

# Save the plot to a file (e.g., a PNG file)
plt.savefig('/home/unicorn/unicon/model2.png', bbox_inches='tight')

# Display the plot
plt.show()

#model3
#model1
# Set a Seaborn style (optional but enhances aesthetics)
sns.set(style="whitegrid")

# Plot the actual values
plt.plot(actuals3, label='Actual Values', color='blue')

# Plot the predicted values
plt.plot(predictions3, label='Predicted Values', color='orange')

# Add labels and title
plt.xlabel('Sample Index', fontsize=14)
plt.ylabel('Energy Consumption', fontsize=14)
plt.title('Actual vs Predicted Total Energy Consumption', fontsize=16)

# Add legend
plt.legend(fontsize=12)

# Customize the plot appearance
plt.grid(True, linestyle='--', alpha=0.3)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

# Save the plot to a file (e.g., a PNG file)
plt.savefig('/home/unicorn/unicon/model3.png', bbox_inches='tight')

from scipy import stats

# Calculate skewness and kurtosis
skewness_before = stats.skew(context_vectors_before_flat)
kurtosis_before = stats.kurtosis(context_vectors_before_flat)

skewness_middle = stats.skew(context_vectors_middle_flat)
kurtosis_middle = stats.kurtosis(context_vectors_middle_flat)

skewness_after = stats.skew(context_vectors_after_flat)
kurtosis_after = stats.kurtosis(context_vectors_after_flat)

# Print the skewness and kurtosis values
print(f'Before Quantization: Skewness={skewness_before}, Kurtosis={kurtosis_before}')
print(f'Middle Quantization: Skewness={skewness_middle}, Kurtosis={kurtosis_middle}')
print(f'After Quantization: Skewness={skewness_after}, Kurtosis={kurtosis_after}')
from sklearn.metrics import mean_squared_error

# Calculate RMSE for each model
rmse_model1 = mean_squared_error(actuals1, predictions1, squared=False)
print("Model 1 RMSE:", rmse_model1)

rmse_model2 = mean_squared_error(actuals2, predictions2, squared=False)
print("Model 2 RMSE:", rmse_model2)

rmse_model3 = mean_squared_error(actuals3, predictions3, squared=False)
print("Model 3 RMSE:", rmse_model3)




# Calculate average inference time per sample for each model
total_inference_time_model1 = end_time1 - start_time1
avg_inference_time_per_sample_model1 = total_inference_time_model1 / len(test_dataset)
print("Average Inference Time Per Sample - Model 1:", avg_inference_time_per_sample_model1)
print("Total Time Per Sample - Model 1:", total_inference_time_model1)

total_inference_time_model2 = end_time2 - start_time2
avg_inference_time_per_sample_model2 = total_inference_time_model2 / len(test_dataset)
print("Average Inference Time Per Sample - Model 2:", avg_inference_time_per_sample_model2)
print("Total Time Per Sample - Model 2:", total_inference_time_model2)

total_inference_time_model3 = end_time3 - start_time3
avg_inference_time_per_sample_model3 = total_inference_time_model3 / len(test_dataset)
print("Average Inference Time Per Sample - Model 3:", avg_inference_time_per_sample_model3)
print("Total Time Per Sample - Model 3:", total_inference_time_model3)

# Convert lists to NumPy arrays
context_vectors_before_np = np.concatenate(context_vectors_before)
context_vectors_middle_np = np.concatenate(context_vectors_middle)
context_vectors_after_np = np.concatenate(context_vectors_after)

# Flatten the arrays for histogram
context_vectors_before_flat = context_vectors_before_np.flatten()
context_vectors_middle_flat = context_vectors_middle_np.flatten()
context_vectors_after_flat = context_vectors_after_np.flatten()



